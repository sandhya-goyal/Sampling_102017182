{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Sandhya Goyal\n",
    "\n",
    "Roll No : 102017182\n",
    "\n",
    "Group : CS8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "767    0\n",
      "768    0\n",
      "769    0\n",
      "770    0\n",
      "771    0\n",
      "Name: Class, Length: 772, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "df = pd.read_csv(\"Creditcard_data.csv\")\n",
    "x=df.iloc[:,:30]\n",
    "y=df.iloc[:,-1]\n",
    "print(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1      9\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def sampling1(X_train,y_train):\n",
    "    X_sampled,y_sampled = RandomUnderSampler.fit_resample(X_train,y_train)\n",
    "    return X_sampled,y_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def sampling2():\n",
    "    X_sampled,y_sampled = RandomOverSampler.fit_resample(X_train,y_train)\n",
    "    return X_sampled,y_sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def sampling3(X_train,y_train):\n",
    "    X_sampled,y_sampled = SMOTE.fit_resample(X_train,y_train)\n",
    "    return X_sampled,y_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "def sampling4(sampling_strategy='majority'):\n",
    "    X_sampled,y_sampled = TomekLinks.fit_resample(X_train,y_train)\n",
    "    return X_sampled,y_sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import \n",
    "\n",
    "def sampling5():\n",
    "    X_sampled,y_sampled = NearMiss.fit_resample(X_train,y_train)\n",
    "    return X_sampled,y_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df = {}\n",
    "final_df['KNN']=[]\n",
    "final_df['Randomforest']=[]\n",
    "final_df['SVC']=[]\n",
    "final_df['Naivebayes']=[]\n",
    "final_df['Decision_tree']=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def model1(X_train, y_train,X_test,y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=2) # by default n_neighbors = 5\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    ac = accuracy_score(y_pred=y_pred,y_true=y_test)\n",
    "    final_df['KNN'].append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def model2(X_train, y_train,X_test,y_test):\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion ='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    ac = accuracy_score(y_pred=y_pred,y_true=y_test)\n",
    "    final_df['Randomforest'].append(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def model3(X_train, y_train,X_test,y_test):\n",
    "    svr_lin = SVC(kernel='linear', C=100, gamma='auto')\n",
    "    svr_lin.fit(X_train,y_train)\n",
    "    y_pred = svr_lin.predict(X_test)\n",
    "    ac = accuracy_score(y_pred=y_pred,y_true=y_test)\n",
    "    final_df['SVC'].append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def model4(X_train, y_train,X_test,y_test):\n",
    "    classifier = GaussianNB()  \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    ac = accuracy_score(y_pred=y_pred,y_true=y_test)\n",
    "    final_df['Naivebayes'].append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def model5(X_train, y_train,X_test,y_test):\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0) \n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    ac = accuracy_score(y_pred=y_pred,y_true=y_test)\n",
    "    final_df['Decision_tree'].append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.0\n"
     ]
    }
   ],
   "source": [
    "# Sample size\n",
    "z = 1.96 # 95% confidence\n",
    "e = 0.05\n",
    "p = 0.05    # 5% frauds\n",
    "\n",
    "n = (z**2 * p * (1-p) )//(e**2)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Define population and sample size\n",
    "def sample1(df):\n",
    "    n= len(df)\n",
    "    # interval =int(len(df) / n)\n",
    "    interval=int(math.sqrt(n))\n",
    "    start = random.uniform(0, interval)\n",
    "    # sample = df.iloc[[int(start + i*interval) for i in range(n)]]\n",
    "    sample=df.iloc[::interval]\n",
    "    return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_n(X,y,n):\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    df = pd.concat((X,y),axis=1).sample(int(n),replace=True)\n",
    "    print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(df):\n",
    "    clusters = random.sample(list(df['Class'].unique()), 2)\n",
    "\n",
    "    # Create a DataFrame containing the selected clusters\n",
    "    cluster_data = pd.concat([df[df['Class'] == c] for c in clusters])\n",
    "    return cluster_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified1(df):\n",
    "    df_sample = df.groupby(\"Class\", group_keys=False).apply(lambda x:x.sample(frac=0.6))\n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified2(df):\n",
    "    df_sample = df.groupby('Class', group_keys=False).apply(lambda x: x.sample(n=72))\n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6   \\\n",
      "240   160.000000 -1.551482 -1.053346  0.762806  1.335129 -2.585523  1.942252   \n",
      "1391  504.732961 -0.424552  0.390487  1.410738  0.299691  0.661341 -0.939355   \n",
      "198   131.000000 -1.007391  1.261943  1.207203  1.307575  0.153211  0.062291   \n",
      "262   184.000000 -0.143256  0.743649  1.534072  1.062170  0.208187 -0.838623   \n",
      "1456  519.247338 -1.768133 -1.868349  2.309802  0.932564  2.137870  0.270199   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "902   557.206969  0.900873  0.523399  0.115325  1.021228 -0.374225 -1.103373   \n",
      "733   551.000000 -0.474661  0.316097  2.446240  0.961007  0.311652  1.857654   \n",
      "1091  319.555803 -1.460028  1.451559 -0.873381  2.610890 -0.041696 -0.827142   \n",
      "287   206.000000 -1.499761  1.059588  0.496912  1.006069 -0.672949 -0.490299   \n",
      "797   477.532082 -2.068302 -1.518197  1.389347  1.317777  1.178437 -0.989301   \n",
      "\n",
      "            7         8         9   ...        21        22        23  \\\n",
      "240   1.646687  0.641266 -0.649862  ...  0.867609  1.254201  1.572315   \n",
      "1391  0.698237 -0.168963 -0.106048  ... -0.015014  0.027506 -0.169130   \n",
      "198   0.508647  0.079447 -0.395211  ...  0.039150  0.411661 -0.080320   \n",
      "262   0.524151 -0.294661 -0.478856  ... -0.205014 -0.460893  0.047407   \n",
      "1456 -1.462346  0.583555  0.720210  ...  0.345276  0.997303  0.177380   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "902  -0.168785 -0.050171 -0.263884  ... -0.206481 -0.742130  0.068400   \n",
      "733  -0.067269  0.482407  0.274670  ...  0.181600  1.047609  0.118818   \n",
      "1091 -1.525167  0.944376 -1.824547  ...  0.286480 -0.158959 -0.245092   \n",
      "287   1.102433 -0.084854 -0.599233  ...  0.082710  0.610348  0.257934   \n",
      "797   0.580715 -0.108729 -0.211559  ...  0.387239  0.364436  0.622712   \n",
      "\n",
      "            24        25        26        27        28          29  0   \n",
      "240  -0.356254 -0.210821 -0.229607 -0.205431  0.039258  700.000000   0  \n",
      "1391  0.375649  0.351956 -0.327556 -0.085498 -0.089665    1.066806   1  \n",
      "198   0.121235 -0.133000 -0.303177 -0.463913 -0.164157   10.000000   0  \n",
      "262   0.339243 -0.779439  0.234456 -0.024125 -0.049898    1.980000   0  \n",
      "1456 -0.587825 -0.087024  0.576052 -0.120250 -0.161244    1.391637   1  \n",
      "...        ...       ...       ...       ...       ...         ...  ..  \n",
      "902   0.340836  0.203467  0.102733  0.006133  0.013529    1.161054   1  \n",
      "733  -0.607102 -0.918465 -0.344381  0.141438 -0.044958   23.970000   0  \n",
      "1091 -0.281398 -0.467573  0.141252  0.250645 -0.009878    0.353635   1  \n",
      "287   0.426521 -0.145909 -0.348520 -0.215146 -0.027602  153.910000   0  \n",
      "797   0.019307  0.331117 -0.287578 -0.184394 -0.038702  285.588394   1  \n",
      "\n",
      "[72 rows x 31 columns]\n",
      "{'KNN': [0.5555555555555556], 'Randomforest': [0.8333333333333334], 'SVC': [0.8888888888888888], 'Naivebayes': [0.6666666666666666], 'Decision_tree': [0.7777777777777778]}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Creditcard_data.csv\")\n",
    "x=df.iloc[:,:30]\n",
    "y=df.iloc[:,-1]\n",
    "x,y=SMOTE().fit_resample(x.values,y.values)\n",
    "df2=get_random_n(x,y,n)\n",
    "x=df2.iloc[:,:-1]\n",
    "y=df2.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "model1(X_train,y_train,X_test,y_test)\n",
    "model2(X_train,y_train,X_test,y_test)\n",
    "model3(X_train,y_train,X_test,y_test)\n",
    "model4(X_train,y_train,X_test,y_test)\n",
    "model5(X_train,y_train,X_test,y_test)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNN': [0.5555555555555556, 0.7], 'Randomforest': [0.8333333333333334, 0.8], 'SVC': [0.8888888888888888, 0.8], 'Naivebayes': [0.6666666666666666, 0.7], 'Decision_tree': [0.7777777777777778, 0.6]}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Creditcard_data.csv\")\n",
    "x=df.iloc[:,:30]\n",
    "y=df.iloc[:,-1]\n",
    "x,y=SMOTE().fit_resample(x.values,y.values)\n",
    "df3 = pd.DataFrame(x)\n",
    "df3['Class']=y\n",
    "df2=sample1(df3)\n",
    "x=df2.iloc[:,:-1]\n",
    "y=df2.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "model1(X_train,y_train,X_test,y_test)\n",
    "model2(X_train,y_train,X_test,y_test)\n",
    "model3(X_train,y_train,X_test,y_test)\n",
    "model4(X_train,y_train,X_test,y_test)\n",
    "model5(X_train,y_train,X_test,y_test)\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNN': [0.5555555555555556, 0.7, 0.8507853403141361], 'Randomforest': [0.8333333333333334, 0.8, 0.9947643979057592], 'SVC': [0.8888888888888888, 0.8, 0.9345549738219895], 'Naivebayes': [0.6666666666666666, 0.7, 0.756544502617801], 'Decision_tree': [0.7777777777777778, 0.6, 0.9554973821989529]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2=clustering(df3)\n",
    "x=df2.iloc[:,:-1]\n",
    "y=df2.iloc[:,-1]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "model1(X_train,y_train,X_test,y_test)\n",
    "model2(X_train,y_train,X_test,y_test)\n",
    "model3(X_train,y_train,X_test,y_test)\n",
    "model4(X_train,y_train,X_test,y_test)\n",
    "model5(X_train,y_train,X_test,y_test)\n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6   \\\n",
      "665   503.000000  0.860545 -0.747804 -0.955151 -1.124056  0.186536 -0.385942   \n",
      "395   287.000000  1.030072 -0.295088 -0.109924  0.071540 -0.318253 -0.912976   \n",
      "474   351.000000  1.205444  0.008467  0.953782  1.141093 -0.491215  0.297303   \n",
      "183   118.000000  1.431053 -0.648101 -0.331664 -1.207383 -0.012786  0.704440   \n",
      "530   394.000000  1.293053  0.457969 -1.940450  0.173149  2.609570  3.014117   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "1123  527.291046 -1.959838 -2.385592  2.439577  1.103695  2.405211  0.537477   \n",
      "859   479.134215 -2.913000 -3.074472  1.261021  2.144884  1.497759 -0.857169   \n",
      "857    82.868692  1.236140  0.325238  0.261995  0.620184 -0.243006 -0.776137   \n",
      "1029  537.979805 -1.765310 -0.207229  1.317651 -0.473353  1.077875 -0.201394   \n",
      "1518  307.450287 -0.375496  0.482518  1.029834  0.145317  0.887248 -0.265158   \n",
      "\n",
      "            7         8         9   ...        20        21        22  \\\n",
      "665   0.703443 -0.282689  0.482600  ...  0.546757 -0.236279 -1.185203   \n",
      "395   0.431930 -0.302891 -0.044433  ...  0.279361 -0.458490 -1.726680   \n",
      "474  -0.503913  0.084948  0.796497  ... -0.035563 -0.103663 -0.046173   \n",
      "183  -0.732126  0.183139 -0.878334  ...  0.100777  0.112749  0.222296   \n",
      "530  -0.269415  0.754420 -0.221009  ...  0.025020 -0.121126 -0.427753   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1123 -1.996662  0.752461  0.917000  ...  0.592827  0.408929  1.160682   \n",
      "859   0.020711  0.039362 -0.117034  ...  1.916919  0.631752  0.530590   \n",
      "857   0.037483 -0.117110 -0.051358  ... -0.076579 -0.269188 -0.774921   \n",
      "1029  0.026352  0.206711  0.118887  ...  0.066015 -0.118130 -0.050491   \n",
      "1518  0.557531  0.006766 -0.131598  ... -0.077256 -0.041293 -0.084582   \n",
      "\n",
      "            23        24        25        26        27        28          29  \n",
      "665  -0.329844 -1.027355  0.613308 -0.979857 -0.018398  0.046621  268.930000  \n",
      "395   0.087429 -0.108541 -0.023411  0.525921 -0.120269  0.031205  160.000000  \n",
      "474  -0.123765 -0.430029  0.559222 -0.360379  0.077359  0.032499   12.990000  \n",
      "183  -0.244591 -1.688158  0.609778 -0.088366  0.010438 -0.014499   20.000000  \n",
      "530  -0.159336  0.857135  0.850055 -0.311685  0.037536  0.050618    1.000000  \n",
      "...        ...       ...       ...       ...       ...       ...         ...  \n",
      "1123  0.276729 -0.809919 -0.196139  0.811084 -0.123856 -0.169340    1.481012  \n",
      "859   1.241025 -0.364307  0.217327 -0.019401 -0.236734  0.009878  462.977225  \n",
      "857   0.120106  0.137192  0.201423  0.103990 -0.019076  0.026078    2.690000  \n",
      "1029 -0.204777 -0.300691 -0.323235  0.303646 -0.322633 -0.361884    1.051010  \n",
      "1518 -0.032326 -0.579764 -0.591049 -0.161848  0.081038  0.070611    0.994483  \n",
      "\n",
      "[916 rows x 30 columns]\n",
      "665     0\n",
      "395     0\n",
      "474     0\n",
      "183     0\n",
      "530     0\n",
      "       ..\n",
      "1123    1\n",
      "859     1\n",
      "857     1\n",
      "1029    1\n",
      "1518    1\n",
      "Name: Class, Length: 916, dtype: int64\n",
      "{'KNN': [0.5555555555555556, 0.7, 0.8507853403141361, 0.834061135371179, 0.7903930131004366], 'Randomforest': [0.8333333333333334, 0.8, 0.9947643979057592, 1.0, 0.9912663755458515], 'SVC': [0.8888888888888888, 0.8, 0.9345549738219895, 0.9344978165938864, 0.9432314410480349], 'Naivebayes': [0.6666666666666666, 0.7, 0.756544502617801, 0.7860262008733624, 0.8253275109170306], 'Decision_tree': [0.7777777777777778, 0.6, 0.9554973821989529, 0.982532751091703, 0.9737991266375546]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2=stratified1(df3)\n",
    "x=df2.iloc[:,:-1]\n",
    "y=df2.iloc[:,-1]\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "model1(X_train,y_train,X_test,y_test)\n",
    "model2(X_train,y_train,X_test,y_test)\n",
    "model3(X_train,y_train,X_test,y_test)\n",
    "model4(X_train,y_train,X_test,y_test)\n",
    "model5(X_train,y_train,X_test,y_test)\n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6   \\\n",
      "371   271.000000  1.196193  0.245161  0.631947  0.642941 -0.413133 -0.699728   \n",
      "583   436.000000 -0.850529  0.963376  1.654453 -0.592041  0.534175 -0.138950   \n",
      "660   499.000000  1.255439  0.307729  0.292700  0.699873 -0.428876 -1.088456   \n",
      "616   464.000000  1.157235  0.138019  0.384987  1.403600 -0.222512 -0.197943   \n",
      "447   324.000000 -0.622317  0.656826  1.094225  0.054665  0.746405 -0.973848   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "806   517.936937 -1.428191  0.185036  1.399248 -0.335220  0.938149 -0.525096   \n",
      "1144  490.761840 -1.946639  0.741585  0.172638  1.031523  0.397326 -0.703356   \n",
      "1525  506.070547 -2.058666 -1.666393  1.707121  1.672809  1.905701  0.217547   \n",
      "1227  420.831652 -2.274646  1.415704 -1.118236  3.653298 -0.162346 -1.182871   \n",
      "1216  466.871047 -2.157991 -0.249004  0.407802  2.583593  0.954652 -0.426475   \n",
      "\n",
      "            7         8         9   ...        20        21        22  \\\n",
      "371   0.019533 -0.112500 -0.047057  ... -0.109478 -0.203868 -0.533641   \n",
      "583   0.939027 -0.096405 -0.247000  ... -0.048380 -0.210381 -0.516510   \n",
      "660   0.043840 -0.167739  0.128854  ... -0.121156 -0.294795 -0.882126   \n",
      "616   0.018264  0.029727  0.412466  ... -0.234543 -0.108900 -0.124281   \n",
      "447   0.386710 -0.009876 -0.351714  ...  0.261014 -0.259937 -0.798558   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "806   0.502666  0.026806 -0.039948  ... -0.043463 -0.085375 -0.010735   \n",
      "1144 -0.748804  0.594370 -0.989738  ...  0.047925  0.073171 -0.135098   \n",
      "1525 -2.189821  0.900815  0.263674  ...  0.528810  0.440121  0.966017   \n",
      "1227 -2.485874  1.318909 -2.320449  ...  0.186477  0.505804  0.113321   \n",
      "1216 -2.325969  1.093087 -0.924707  ...  0.371379  0.470327  0.573880   \n",
      "\n",
      "            23        24        25        26        27        28         29  \n",
      "371   0.201929  0.406872  0.116137  0.102675 -0.009121  0.019700   0.890000  \n",
      "583  -0.400127 -0.406340  0.621244  0.201347 -0.135415  0.046320  15.800000  \n",
      "660   0.136846  0.327949  0.194459  0.096516 -0.027271  0.029491   1.980000  \n",
      "616  -0.055454  0.072990  0.634638 -0.310493  0.033931  0.014937  11.990000  \n",
      "447   0.000086 -0.199902 -0.062407  0.104703  0.230467  0.102421   0.890000  \n",
      "...        ...       ...       ...       ...       ...       ...        ...  \n",
      "806  -0.260381  0.001057 -0.056948 -0.025522 -0.252957 -0.284836   1.000000  \n",
      "1144 -0.335626 -0.035212 -0.197377  0.217660 -0.125238 -0.296413   0.637307  \n",
      "1525  0.155590 -0.637634 -0.170137  0.733662 -0.052708 -0.165881   1.220373  \n",
      "1227 -0.373201  0.178236  0.012705  0.260219  0.214628 -0.146626   0.180874  \n",
      "1216 -0.087589 -0.262433 -0.086052  0.515936  0.070234 -0.157026   0.742330  \n",
      "\n",
      "[144 rows x 30 columns]\n",
      "371     0\n",
      "583     0\n",
      "660     0\n",
      "616     0\n",
      "447     0\n",
      "       ..\n",
      "806     1\n",
      "1144    1\n",
      "1525    1\n",
      "1227    1\n",
      "1216    1\n",
      "Name: Class, Length: 144, dtype: int64\n",
      "{'KNN': [0.5555555555555556, 0.7, 0.8507853403141361, 0.834061135371179, 0.7903930131004366, 0.8055555555555556], 'Randomforest': [0.8333333333333334, 0.8, 0.9947643979057592, 1.0, 0.9912663755458515, 0.9166666666666666], 'SVC': [0.8888888888888888, 0.8, 0.9345549738219895, 0.9344978165938864, 0.9432314410480349, 0.8611111111111112], 'Naivebayes': [0.6666666666666666, 0.7, 0.756544502617801, 0.7860262008733624, 0.8253275109170306, 0.8333333333333334], 'Decision_tree': [0.7777777777777778, 0.6, 0.9554973821989529, 0.982532751091703, 0.9737991266375546, 0.9444444444444444]}\n"
     ]
    }
   ],
   "source": [
    "df2=stratified2(df3)\n",
    "x=df2.iloc[:,:-1]\n",
    "y=df2.iloc[:,-1]\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "model1(X_train,y_train,X_test,y_test)\n",
    "model2(X_train,y_train,X_test,y_test)\n",
    "model3(X_train,y_train,X_test,y_test)\n",
    "model4(X_train,y_train,X_test,y_test)\n",
    "model5(X_train,y_train,X_test,y_test)\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'KNN': [0.5555555555555556, 0.7, 0.8507853403141361, 0.834061135371179, 0.7903930131004366, 0.8055555555555556], 'Randomforest': [0.8333333333333334, 0.8, 0.9947643979057592, 1.0, 0.9912663755458515, 0.9166666666666666], 'SVC': [0.8888888888888888, 0.8, 0.9345549738219895, 0.9344978165938864, 0.9432314410480349, 0.8611111111111112], 'Naivebayes': [0.6666666666666666, 0.7, 0.756544502617801, 0.7860262008733624, 0.8253275109170306, 0.8333333333333334], 'Decision_tree': [0.7777777777777778, 0.6, 0.9554973821989529, 0.982532751091703, 0.9737991266375546, 0.9444444444444444]}\n"
     ]
    }
   ],
   "source": [
    "print(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "229cdfb8eedfa4964725b7eb0da8d7a63b25d97a6ab808f09bd6b506844c0629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
